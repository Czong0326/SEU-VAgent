import json
import os

def merge_datasets(base_path):
    """åˆå¹¶å¤šå±‚çº§æ•°æ®é›†"""
    # å®šä¹‰ç›®æ ‡æ–‡ä»¶è·¯å¾„
    output_path = os.path.join(base_path, "dataset_train.json")
    
    # é…ç½®éœ€è¦åˆå¹¶çš„æ–‡ä»¶ç»“æ„
    dataset_map = {
        "first": "dataset_first.json",
        "second": "dataset_second.json",
        "third": "dataset_third.json",
        "fourth": "dataset_fourth.json"
    }

    merged_data = []
    
    # éå†æ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹
    for folder, filename in dataset_map.items():
        file_path = os.path.join(base_path, folder, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                print(f"ğŸ” æ­£åœ¨åŠ è½½ï¼š{folder}/{filename}")
                data = json.load(f)
                
                # æ•°æ®æ ¼å¼éªŒè¯
                if not isinstance(data, list):
                    raise ValueError(f"æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼š{file_path} ä¸æ˜¯JSONæ•°ç»„")
                
                merged_data.extend(data)
                print(f"âœ… æˆåŠŸåŠ è½½ {len(data)} æ¡è®°å½•")
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å¤±è´¥ï¼š{folder}/{filename} - {str(e)}")
            continue

    # å†™å…¥åˆå¹¶æ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ åˆå¹¶å®Œæˆï¼æ€»æ ·æœ¬é‡ï¼š{len(merged_data)}")
    print(f"è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")

# ä½¿ç”¨ç¤ºä¾‹
base_dir = r"C:\Users\æœ±æƒæµ·\Desktop\llm\dataset"
merge_datasets(base_dir)
